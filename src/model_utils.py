from typing import Tuple, Dict, Callable, Optional, List
import os

import keras
import numpy as np
import tqdm

import cnn_model
import image_utils
import non_standard_models

__model_string_mapping: Dict[str, Callable[[Tuple[int, int, int], Optional[bool]], keras.Model]] = {
    "cnn": cnn_model.create_model,
    "reimage": non_standard_models.create_reimaging_model,
    "recurrent": non_standard_models.create_recurrent_model,
    "granular": non_standard_models.create_granular_model
}


def create_model(model_id: str, input_shape: Tuple[int, int, int]) -> keras.Model:
    return __model_string_mapping[model_id](input_shape)


def custom_accuracy(model: keras.Model, image_size: Tuple[int, int], normalize_images,
                    images_per_batch: int = 400, image_dir: str = "val_images",
                    prediction_stats_storage: Dict[int, List[int]] = {}) -> float:
    """
    Load all images in the directory in batches, and calculate accuracy of the model from its predictions on the images.
    :param model: Model to test the accuracy of
    :param image_size: Size the images should be resized to after loading from disk
    :param normalize_images: Whether to normalize the images when loading.
        Best results have been observed with normalization, but experimentation with removing normalization is viable.
    :param images_per_batch: The number of images to load into memory at one time
    :param image_dir: Directory to load the images from
    :param prediction_stats_storage: Dictionary to store prediction statistics in. When a dictionary is not supplied, an empty
        one is generated, but is not accessible. Any dictionary passed in will be cleared prior to being filled.
    :return: Accuracy of the predictions generated by the model for the images in the directory. Accuracy is in the
        range [0.0, 1.0]
    """
    val_image_files = os.listdir(image_dir)
    prediction_stats_storage.clear()
    curr_index = 0
    num_correct = 0
    num_iterations = (len(val_image_files) // images_per_batch) + 1
    print("Custom Accuracy Batches:")
    for _ in tqdm.tqdm(range(num_iterations)):
        batch_image_paths = val_image_files[curr_index: curr_index + images_per_batch]
        batch_image_paths = [image_dir + os.path.sep + x for x in batch_image_paths]
        batch_images, batch_labels = image_utils.load_specified_batch(batch_image_paths, image_size, normalize_images)
        predicted_labels = model.predict(batch_images)
        for index, predicted in enumerate(predicted_labels):
            predicted_label = np.argmax(predicted)
            actual_label = np.argmax(batch_labels[index])
            if predicted_label == actual_label:
                num_correct += 1
            if actual_label not in prediction_stats_storage:
                prediction_stats_storage[actual_label] = [0] * len(predicted)
            prediction_stats_storage[actual_label][predicted_label] += 1
        curr_index += images_per_batch
    return num_correct / len(val_image_files)


def train_model(model: keras.Model, num_batches: int, epochs_per_batch: int,
                image_size: Tuple[int, int], train_images_per_batch: int = 1000,
                val_images_per_batch: int = 400, normalize_images: bool = False, print_statistics: bool = True) -> None:
    for _ in range(num_batches):
        train_images, train_labels = image_utils.load_batch("train_images", train_images_per_batch,
                                                            image_size, normalize_images)
        for _ in range(epochs_per_batch):
            model.fit(train_images, train_labels, epochs=1)
            prediction_stats = {}
            accuracy = custom_accuracy(model, image_size,
                                       val_images_per_batch, prediction_stats_storage=prediction_stats)
            print(f"Calculated val_acc: {accuracy}")
            if print_statistics:
                print_prediction_stats(prediction_stats)


def print_prediction_stats(prediction_stats: Dict[int, List[int]]) -> None:
    prediction_stats_mat = np.zeros((len(prediction_stats), len(prediction_stats[0])))
    for actual, stats in prediction_stats.items():
        for index, stat in enumerate(stats):
            prediction_stats_mat[actual][index] = stat
    confusion_mat = np.zeros_like(prediction_stats_mat)
    for stat_index, stats in enumerate(prediction_stats_mat):
        total = sum(stats)
        for index, stat in enumerate(stats):
            confusion_mat[stat_index][index] = stat / total
    print(f"Model prediction statistics:\n{prediction_stats_mat}\n{confusion_mat}")


def save_model(model: keras.Model, file_path: str):
    directory, file = os.path.split(file_path)
    if not os.path.exists(directory):
        os.mkdir(directory)
    model.save(file_path)


def load_model(file_path: str) -> keras.Model:
    # let keras raise the error if the file doesn't exist.
    return keras.models.load_model(file_path)
